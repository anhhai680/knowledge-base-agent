# LLM Configuration
LLM_PROVIDER=ollama  # Options: openai, gemini, azure_openai
LLM_MODEL=gpt-3.5-turbo  # Change to your preferred model

LLM_API_BASE_URL=http://localhost:11434  # Change if using a different provider

# Embedding Configuration
# Change to your preferred embedding model
EMBEDDING_MODEL= nomic-embed-text  #text-embedding-ada-002
EMBEDDING_API_BASE_URL=http://localhost:11434  # Change if using a different provider

# API Keys
# Replace with your actual API keys for the respective providers
# Ensure to keep these keys secure and do not expose them in public repositories
OPENAI_API_KEY=your_openai_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here
AZURE_OPENAI_API_KEY=your_azure_openai_key
AZURE_OPENAI_ENDPOINT=your_azure_endpoint

# Vector Database Configuration
CHROMA_HOST=localhost
CHROMA_PORT=8000
CHROMA_COLLECTION_NAME=knowledge-base-collection

# PostgreSQL Configuration (for pgvector)
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=knowledge_base
POSTGRES_USER=postgres
POSTGRES_PASSWORD=password

# GitHub Configuration
GITHUB_TOKEN=your_github_token_here
GITHUB_REPOS=["https://github.com/user/repo1", "https://github.com/user/repo2"]

# Application Configuration
APP_ENV=development
LOG_LEVEL=INFO
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_TOKENS=4000
TEMPERATURE=0.7

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
